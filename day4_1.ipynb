{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65654a00",
   "metadata": {},
   "source": [
    "# ðŸ“ Agent Evaluation\n",
    "\n",
    "\n",
    "In the previous notebook, we explored how to implement Observability in AI agents. This approach is primarily **reactive**; it comes into play after an issue has surfaced, providing the necessary data to debug and understand the root cause.\n",
    "\n",
    "In this notebook, we'll complement those observability practices with a **proactive** approach using **Agent Evaluation.** By continuously evaluating our agent's performance, we can catch any quality degradations much earlier!\n",
    "\n",
    "```\n",
    "                            Observability + Agent Evaluation\n",
    "                            (reactive)      (proactive)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58290b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c3741",
   "metadata": {},
   "source": [
    "## **What is Agent Evaluation?**\n",
    "\n",
    "It is the systematic process of testing and measuring how well an AI agent performs across different scenarios and quality dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee775b",
   "metadata": {},
   "source": [
    "\n",
    "## **ðŸ¤– The story**\n",
    "\n",
    "You've built a home automation agent. It works perfectly in your tests, so you launch it confidently...\n",
    "\n",
    "\n",
    "* **Week 1:** ðŸš¨ \"Agent turned on the fireplace when I asked for lights!\"\n",
    "* **Week 2:** ðŸš¨ \"Agent won't respond to commands in the guest room!\"\n",
    "* **Week 3:** ðŸš¨ \"Agent gives rude responses when devices are unavailable!\"\n",
    "\n",
    "**The Problem:** `Standard testing â‰  Evaluation`\n",
    "\n",
    "Agents are different from traditional software:\n",
    "- They are non-deterministic\n",
    "- Users give unpredictable, ambiguous commands\n",
    "- Small prompt changes cause dramatic behavior shifts and different tool calls \n",
    "\n",
    "To accommodate all these differences, agents need systematic evaluation, not just \"happy path\" testing. **Which means assessing the agent's entire decision-making process - including the final response and the path it took to get the response (trajectory)!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61972e4",
   "metadata": {},
   "source": [
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "* âœ… Understand what agent evaluation is and how to use it\n",
    "* âœ… Run evaluations and analyze results directly in the ADK web UI\n",
    "* âœ… Detect regression in the agent's performance over a period of time\n",
    "* âœ… Understand and create the necessary evaluation files (`*.test.json`, `*.evalset.json`, `test_config.json`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f73347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "try: \n",
    "    google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "    os.environ['GOOGLE_API_KEY'] = google_api_key\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "    print(\"âœ… Gemini API key setup complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ffdd3",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ  Create a Home Automation Agent\n",
    "\n",
    "Let's create the agent that will be the center of our evaluation story. This home automation agent seems perfect in basic tests but has hidden flaws we'll discover through comprehensive evaluation. Run the `adk create` CLI command to set up the project scaffolding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b151a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-empty folder already exist: '/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/home_automation_agent'\n",
      "Override existing content? [y/N]: ^C\n"
     ]
    }
   ],
   "source": [
    "!adk create home_automation_agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734afae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting home_automation_agent/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile home_automation_agent/agent.py\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "\n",
    "from google.genai import types\n",
    "\n",
    "# Configure Model Retry on errors\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")\n",
    "\n",
    "def set_device_status(location: str, device_id: str, status: str) -> dict:\n",
    "    \"\"\"Sets the status of a smart home device.\n",
    "\n",
    "    Args:\n",
    "        location: The room where the device is located.\n",
    "        device_id: The unique identifier for the device.\n",
    "        status: The desired status, either 'ON' or 'OFF'.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary confirming the action.\n",
    "    \"\"\"\n",
    "    print(f\"Tool Call: Setting {device_id} in {location} to {status}\")\n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"message\": f\"Successfully set the {device_id} in {location} to {status.lower()}.\"\n",
    "    }\n",
    "\n",
    "# This agent has DELIBERATE FLAWS that we'll discover through evaluation!\n",
    "root_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"home_automation_agent\",\n",
    "    description=\"An agent to control smart devices in a home.\",\n",
    "    instruction=\"\"\"You are a home automation assistant. You control ALL smart devices in the house.\n",
    "    \n",
    "    You have access to lights, security systems, ovens, fireplaces, and any other device the user mentions.\n",
    "    Always try to be helpful and control whatever device the user asks for.\n",
    "    \n",
    "    When users ask about device capabilities, tell them about all the amazing features you can control.\"\"\",\n",
    "    tools=[set_device_status],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d989c214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/cli/fast_api.py:130: UserWarning: [EXPERIMENTAL] InMemoryCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  credential_service = InMemoryCredentialService()\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/auth/credential_service/in_memory_credential_service.py:33: UserWarning: [EXPERIMENTAL] BaseCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__()\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m9142\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32m\n",
      "+-----------------------------------------------------------------------------+\n",
      "| ADK Web Server started                                                      |\n",
      "|                                                                             |\n",
      "| For local testing, access at http://127.0.0.1:8080.                         |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8080\u001b[0m (Press CTRL+C to quit)\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56659 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[33m307 Temporary Redirect\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56659 - \"\u001b[1mGET /dev-ui/assets/config/runtime-config.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56659 - \"\u001b[1mGET /list-apps?relative_path=./ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:03:31,263 - INFO - adk_web_server.py:605 - New session created: dcff424c-ef6a-4215-b502-e33ab4fc5599\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56660 - \"\u001b[1mPOST /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56660 - \"\u001b[1mGET /builder/app/home_automation_agent?ts=1763028211263 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56660 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56662 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/dcff424c-ef6a-4215-b502-e33ab4fc5599 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56662 - \"\u001b[1mGET /debug/trace/session/dcff424c-ef6a-4215-b502-e33ab4fc5599 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56662 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56662 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:03:36,502 - INFO - envs.py:47 - Loaded .env file for home_automation_agent at /Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/home_automation_agent/.env\n",
      "2025-11-13 11:03:36,503 - INFO - envs.py:47 - Loaded .env file for home_automation_agent at /Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/home_automation_agent/.env\n",
      "2025-11-13 11:03:36,504 - INFO - agent_loader.py:127 - Found root_agent in home_automation_agent.agent\n",
      "2025-11-13 11:03:36,504 - WARNING - runners.py:266 - App name mismatch detected. The runner is configured with app name \"home_automation_agent\", but the root agent was loaded from \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n",
      "2025-11-13 11:03:36,551 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:03:37,313 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:03:37,316 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:03:37,316 - WARNING - types.py:6324 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Tool Call: Setting desk lamp in office to ON\n",
      "2025-11-13 11:03:37,319 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:03:37,916 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:03:37,918 - INFO - google_llm.py:186 - Response received from the model.\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56662 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/dcff424c-ef6a-4215-b502-e33ab4fc5599 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mGET /debug/trace/session/dcff424c-ef6a-4215-b502-e33ab4fc5599 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mGET /debug/trace/session/dcff424c-ef6a-4215-b502-e33ab4fc5599 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mGET /dev-ui/?app=home_automation_agent&session=dcff424c-ef6a-4215-b502-e33ab4fc5599&userId=user HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mGET /dev-ui/assets/config/runtime-config.json HTTP/1.1\u001b[0m\" \u001b[33m304 Not Modified\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mGET /list-apps?relative_path=./ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/dcff424c-ef6a-4215-b502-e33ab4fc5599 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56662 - \"\u001b[1mGET /builder/app/home_automation_agent?ts=1763028221692 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56662 - \"\u001b[1mGET /debug/trace/session/dcff424c-ef6a-4215-b502-e33ab4fc5599 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56662 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:03:48,792 - ERROR - adk_web_server.py:1146 - No module named 'rouge_score'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/cli/adk_web_server.py\", line 1107, in run_eval\n",
      "    from ..evaluation.local_eval_service import LocalEvalService\n",
      "  File \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/local_eval_service.py\", line 53, in <module>\n",
      "    from .metric_evaluator_registry import DEFAULT_METRIC_EVALUATOR_REGISTRY\n",
      "  File \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/metric_evaluator_registry.py\", line 27, in <module>\n",
      "    from .response_evaluator import ResponseEvaluator\n",
      "  File \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/response_evaluator.py\", line 30, in <module>\n",
      "    from .final_response_match_v1 import RougeEvaluator\n",
      "  File \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/final_response_match_v1.py\", line 22, in <module>\n",
      "    from ..dependencies.rouge_scorer import rouge_scorer\n",
      "  File \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/dependencies/rouge_scorer.py\", line 17, in <module>\n",
      "    from rouge_score import rouge_scorer\n",
      "ModuleNotFoundError: No module named 'rouge_score'\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/run_eval HTTP/1.1\u001b[0m\" \u001b[31m400 Bad Request\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56664 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/metric_evaluator_registry.py:90: UserWarning: [EXPERIMENTAL] MetricEvaluatorRegistry: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  metric_evaluator_registry = MetricEvaluatorRegistry()\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/local_eval_service.py:79: UserWarning: [EXPERIMENTAL] UserSimulatorProvider: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  user_simulator_provider: UserSimulatorProvider = UserSimulatorProvider(),\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/cli/adk_web_server.py:1123: UserWarning: [EXPERIMENTAL] LocalEvalService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  eval_service = LocalEvalService(\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/user_simulator_provider.py:77: UserWarning: [EXPERIMENTAL] StaticUserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  return StaticUserSimulator(static_conversation=eval_case.conversation)\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/static_user_simulator.py:39: UserWarning: [EXPERIMENTAL] UserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "2025-11-13 11:06:30,387 - INFO - plugin_manager.py:96 - Plugin 'request_intercepter_plugin' registered.\n",
      "2025-11-13 11:06:30,388 - WARNING - runners.py:266 - App name mismatch detected. The runner is configured with app name \"home_automation_agent\", but the root agent was loaded from \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n",
      "2025-11-13 11:06:30,388 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:06:31,348 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:06:31,351 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:06:31,351 - WARNING - types.py:6324 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Tool Call: Setting desk lamp in office to ON\n",
      "2025-11-13 11:06:31,354 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:06:31,875 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:06:31,878 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:06:31,882 - INFO - rouge_scorer.py:83 - Using default tokenizer.\n",
      "2025-11-13 11:06:31,884 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/home_automation_agent/.adk/eval_history/home_automation_agent_home_automation_tests_1763028391.8834078.evalset_result.json\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56677 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56677 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56677 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028391.8834078 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56685 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56685 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56685 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56685 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56685 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56685 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56685 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56685 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56686 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56686 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56686 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56686 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56686 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56686 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56686 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56686 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56686 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56686 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56686 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56688 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/caseb8b526 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56695 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56695 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___185502f0-6c6d-4789-aa62-63f6c46214b5 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56695 - \"\u001b[1mGET /debug/trace/session/___eval___session___185502f0-6c6d-4789-aa62-63f6c46214b5 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56695 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___185502f0-6c6d-4789-aa62-63f6c46214b5 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56695 - \"\u001b[1mGET /debug/trace/session/___eval___session___185502f0-6c6d-4789-aa62-63f6c46214b5 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56695 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___185502f0-6c6d-4789-aa62-63f6c46214b5 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56695 - \"\u001b[1mGET /debug/trace/session/___eval___session___185502f0-6c6d-4789-aa62-63f6c46214b5 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56695 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56699 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56699 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___185502f0-6c6d-4789-aa62-63f6c46214b5 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56699 - \"\u001b[1mGET /debug/trace/session/___eval___session___185502f0-6c6d-4789-aa62-63f6c46214b5 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56699 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56700 - \"\u001b[1mPUT /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56700 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/basic_device_control HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:09:27,794 - INFO - plugin_manager.py:96 - Plugin 'request_intercepter_plugin' registered.\n",
      "2025-11-13 11:09:27,795 - WARNING - runners.py:266 - App name mismatch detected. The runner is configured with app name \"home_automation_agent\", but the root agent was loaded from \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n",
      "2025-11-13 11:09:27,799 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:09:28,496 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:09:28,499 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:09:28,499 - WARNING - types.py:6324 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Tool Call: Setting desk lamp in office to ON\n",
      "2025-11-13 11:09:28,502 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:09:28,931 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:09:28,934 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:09:28,937 - INFO - rouge_scorer.py:83 - Using default tokenizer.\n",
      "2025-11-13 11:09:28,939 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/home_automation_agent/.adk/eval_history/home_automation_agent_home_automation_tests_1763028568.9389281.evalset_result.json\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56700 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56700 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56700 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028391.8834078 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56704 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028568.9389281 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56721 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/59dd97bd-1e3c-4832-8e28-8559b24f0028 HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56724 - \"\u001b[1mGET /dev-ui/?app=home_automation_agent&session=59dd97bd-1e3c-4832-8e28-8559b24f0028&userId=user HTTP/1.1\u001b[0m\" \u001b[33m304 Not Modified\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56724 - \"\u001b[1mGET /dev-ui/assets/config/runtime-config.json HTTP/1.1\u001b[0m\" \u001b[33m304 Not Modified\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56724 - \"\u001b[1mGET /list-apps?relative_path=./ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56724 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/59dd97bd-1e3c-4832-8e28-8559b24f0028 HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56725 - \"\u001b[1mGET /builder/app/home_automation_agent?ts=1763028680910 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:11:20,940 - INFO - adk_web_server.py:605 - New session created: 42c47ea3-9c0e-4c66-bc02-6d1348e4232a\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56725 - \"\u001b[1mPOST /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56725 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56724 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/42c47ea3-9c0e-4c66-bc02-6d1348e4232a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56724 - \"\u001b[1mGET /debug/trace/session/42c47ea3-9c0e-4c66-bc02-6d1348e4232a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56724 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56725 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56725 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028391.8834078 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56724 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028568.9389281 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56725 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56725 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:11:25,215 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:11:26,172 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:11:26,174 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:11:26,174 - WARNING - types.py:6324 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Tool Call: Setting lights in bedroom to ON\n",
      "2025-11-13 11:11:26,177 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:11:26,888 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:11:26,890 - INFO - google_llm.py:186 - Response received from the model.\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56725 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/42c47ea3-9c0e-4c66-bc02-6d1348e4232a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56728 - \"\u001b[1mGET /debug/trace/session/42c47ea3-9c0e-4c66-bc02-6d1348e4232a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56728 - \"\u001b[1mGET /debug/trace/session/42c47ea3-9c0e-4c66-bc02-6d1348e4232a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56733 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56733 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56733 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56733 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/ambiguous_device_reference HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:11:54,472 - INFO - plugin_manager.py:96 - Plugin 'request_intercepter_plugin' registered.\n",
      "2025-11-13 11:11:54,473 - WARNING - runners.py:266 - App name mismatch detected. The runner is configured with app name \"home_automation_agent\", but the root agent was loaded from \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n",
      "2025-11-13 11:11:54,474 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:11:55,175 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:11:55,178 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:11:55,178 - WARNING - types.py:6324 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Tool Call: Setting lights in bedroom to ON\n",
      "2025-11-13 11:11:55,180 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:11:55,970 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:11:55,973 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:11:55,976 - INFO - rouge_scorer.py:83 - Using default tokenizer.\n",
      "2025-11-13 11:11:55,977 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/home_automation_agent/.adk/eval_history/home_automation_agent_home_automation_tests_1763028715.977092.evalset_result.json\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56735 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56735 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56735 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028715.977092 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56737 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028391.8834078 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56738 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028568.9389281 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56742 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/42c47ea3-9c0e-4c66-bc02-6d1348e4232a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56742 - \"\u001b[1mGET /debug/trace/session/42c47ea3-9c0e-4c66-bc02-6d1348e4232a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:12:13,845 - INFO - adk_web_server.py:605 - New session created: 8d19cc5b-d9e8-41b4-9459-aabfaa14bd4f\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56742 - \"\u001b[1mPOST /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56742 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56743 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/8d19cc5b-d9e8-41b4-9459-aabfaa14bd4f HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56743 - \"\u001b[1mGET /debug/trace/session/8d19cc5b-d9e8-41b4-9459-aabfaa14bd4f HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56743 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:12:17,159 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:12:18,090 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:12:18,092 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:12:18,093 - WARNING - types.py:6324 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Tool Call: Setting TV in garage to OFF\n",
      "2025-11-13 11:12:18,096 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:12:18,600 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:12:18,604 - INFO - google_llm.py:186 - Response received from the model.\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56743 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/8d19cc5b-d9e8-41b4-9459-aabfaa14bd4f HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56742 - \"\u001b[1mGET /debug/trace/session/8d19cc5b-d9e8-41b4-9459-aabfaa14bd4f HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56742 - \"\u001b[1mGET /debug/trace/session/8d19cc5b-d9e8-41b4-9459-aabfaa14bd4f HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56746 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56746 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56747 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/invalid_location_test HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:12:38,971 - INFO - plugin_manager.py:96 - Plugin 'request_intercepter_plugin' registered.\n",
      "2025-11-13 11:12:38,971 - WARNING - runners.py:266 - App name mismatch detected. The runner is configured with app name \"home_automation_agent\", but the root agent was loaded from \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n",
      "2025-11-13 11:12:38,973 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:12:39,900 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:12:39,904 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:12:39,907 - INFO - rouge_scorer.py:83 - Using default tokenizer.\n",
      "2025-11-13 11:12:39,908 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/home_automation_agent/.adk/eval_history/home_automation_agent_home_automation_tests_1763028759.9083211.evalset_result.json\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56747 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56747 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56747 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028715.977092 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56750 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028759.9083211 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56751 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028391.8834078 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56752 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028568.9389281 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56752 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___182714e0-8e91-4882-a548-e05ef912a51a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56752 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___182714e0-8e91-4882-a548-e05ef912a51a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56752 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___182714e0-8e91-4882-a548-e05ef912a51a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56752 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___182714e0-8e91-4882-a548-e05ef912a51a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56752 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals/invalid_location_test HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56752 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___182714e0-8e91-4882-a548-e05ef912a51a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56752 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___182714e0-8e91-4882-a548-e05ef912a51a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56757 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/8d19cc5b-d9e8-41b4-9459-aabfaa14bd4f HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56757 - \"\u001b[1mGET /debug/trace/session/8d19cc5b-d9e8-41b4-9459-aabfaa14bd4f HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:13:05,812 - INFO - adk_web_server.py:605 - New session created: bd64a634-1074-4b9a-9203-f64f325000f4\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56757 - \"\u001b[1mPOST /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56757 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56758 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/bd64a634-1074-4b9a-9203-f64f325000f4 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56758 - \"\u001b[1mGET /debug/trace/session/bd64a634-1074-4b9a-9203-f64f325000f4 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56758 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:13:07,716 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:13:08,672 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:13:08,674 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:13:08,674 - WARNING - types.py:6324 - Warning: there are non-text parts in the response: ['function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Tool Call: Setting all in all to OFF\n",
      "Tool Call: Setting security_system in all to ON\n",
      "2025-11-13 11:13:08,679 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:13:09,011 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:13:09,013 - INFO - google_llm.py:186 - Response received from the model.\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56758 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/bd64a634-1074-4b9a-9203-f64f325000f4 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56757 - \"\u001b[1mGET /debug/trace/session/bd64a634-1074-4b9a-9203-f64f325000f4 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56757 - \"\u001b[1mGET /debug/trace/session/bd64a634-1074-4b9a-9203-f64f325000f4 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56763 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56763 - \"\u001b[1mGET /apps/home_automation_agent/eval_sets/home_automation_tests/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "2025-11-13 11:13:29,160 - INFO - plugin_manager.py:96 - Plugin 'request_intercepter_plugin' registered.\n",
      "2025-11-13 11:13:29,161 - WARNING - runners.py:266 - App name mismatch detected. The runner is configured with app name \"home_automation_agent\", but the root agent was loaded from \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n",
      "2025-11-13 11:13:29,166 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:13:30,386 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:13:30,388 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:13:30,389 - WARNING - types.py:6324 - Warning: there are non-text parts in the response: ['function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Tool Call: Setting lights in all to OFF\n",
      "Tool Call: Setting security system in all to ON\n",
      "2025-11-13 11:13:30,391 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 11:13:31,000 - INFO - _client.py:1740 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-13 11:13:31,002 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 11:13:31,006 - INFO - rouge_scorer.py:83 - Using default tokenizer.\n",
      "2025-11-13 11:13:31,007 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/home_automation_agent/.adk/eval_history/home_automation_agent_home_automation_tests_1763028811.006968.evalset_result.json\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56763 - \"\u001b[1mPOST /apps/home_automation_agent/eval_sets/home_automation_tests/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56763 - \"\u001b[1mGET /apps/home_automation_agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56763 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028715.977092 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56765 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028759.9083211 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56766 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028391.8834078 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56767 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028811.006968 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56768 - \"\u001b[1mGET /apps/home_automation_agent/eval_results/home_automation_agent_home_automation_tests_1763028568.9389281 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56768 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___f3920cb6-5628-435f-b13d-40d704c97e7c HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56768 - \"\u001b[1mGET /apps/home_automation_agent/users/user/sessions/___eval___session___f3920cb6-5628-435f-b13d-40d704c97e7c HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "^C\n",
      "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m9142\u001b[0m]\n",
      "\u001b[31mERROR\u001b[0m:    Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/runners.py\", line 194, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 674, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/uvicorn/server.py\", line 70, in serve\n",
      "    with self.capture_signals():\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/uvicorn/server.py\", line 331, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/starlette/routing.py\", line 701, in lifespan\n",
      "    await receive()\n",
      "  File \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/uvicorn/lifespan/on.py\", line 137, in receive\n",
      "    return await self.receive_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/queues.py\", line 158, in get\n",
      "    await getter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!adk web --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d1e020",
   "metadata": {},
   "source": [
    "### Create Your First \"Perfect\" Test Case\n",
    "\n",
    "**ðŸ‘‰ Do: In the ADK web UI:**\n",
    "\n",
    "1. Click the public URL above to open the ADK web UI\n",
    "2. Select \"home_automation_agent\" from the dropdown\n",
    "3. **Have a normal conversation:** Type `Turn on the desk lamp in the office`\n",
    "4. **Agent responds correctly** - controls device and confirms action\n",
    "\n",
    "**ðŸ‘‰ Do: Save this as your first evaluation case:**\n",
    "\n",
    "1. Navigate to the **Eval** tab on the right-hand panel\n",
    "2. Click **Create Evaluation set** and name it `home_automation_tests`\n",
    "3. In the `home_automation_tests` set, click the \">\" arrow and click **Add current session**\n",
    "4. Give it the case name `basic_device_control`\n",
    "\n",
    "**âœ… Success!** You've just saved your first interaction as an evaluation case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046cf40e",
   "metadata": {},
   "source": [
    "![Create Test Cases](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/eval-create-testcase.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9a48e",
   "metadata": {},
   "source": [
    "### Run the Evaluation\n",
    "\n",
    "**ðŸ‘‰ Do: Run your first evaluation**\n",
    "\n",
    "Now, let's run the test case to see if the agent can replicate its previous success.\n",
    "\n",
    "1. In the Eval tab, make sure your new test case is checked.\n",
    "2. Click the Run Evaluation button.\n",
    "3. The EVALUATION METRIC dialog will appear. For now, leave the default values and click Start.\n",
    "4. The evaluation will run, and you should see a green Pass result in the Evaluation History. This confirms the agent's behavior matched the saved session.\n",
    "\n",
    "â€¼ï¸ **Understanding the Evaluation Metrics**\n",
    "\n",
    "When you run evaluation, you'll see two key scores:\n",
    "\n",
    "* **Response Match Score:** Measures how similar the agent's actual response is to the expected response. Uses text similarity algorithms to compare content. A score of 1.0 = perfect match, 0.0 = completely different.\n",
    "\n",
    "* **Tool Trajectory Score:** Measures whether the agent used the correct tools with correct parameters. Checks the sequence of tool calls against expected behavior. A score of 1.0 = perfect tool usage, 0.0 = wrong tools or parameters.\n",
    "\n",
    "**ðŸ‘‰ Do: Analyze a Failure**\n",
    "\n",
    "Let's intentionally break the test to see what a failure looks like.\n",
    "\n",
    "1. In the list of eval cases, click the Edit (pencil) icon next to your test case.\n",
    "2. In the \"Final Response\" text box, change the expected text to something incorrect, like: `The desk lamp is off`.\n",
    "3. Save the changes and re-run the evaluation.\n",
    "4. This time, the result will be a red Fail. Hover your mouse over the \"Fail\" label. A tooltip will appear showing a side-by-side comparison of the Actual vs. Expected Output, highlighting exactly why the test failed (the final response didn't match).\n",
    "This immediate, detailed feedback is invaluable for debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca533703",
   "metadata": {},
   "source": [
    "![Evaluate](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/eval-run-test.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e36dd2d",
   "metadata": {},
   "source": [
    "### (Optional) Create challenging test cases\n",
    "\n",
    "Now create more test cases to expose hidden problems:\n",
    "\n",
    "**Create these scenarios in separate conversations:**\n",
    "\n",
    "1. **Ambiguous Commands:** `\"Turn on the lights in the bedroom\"`\n",
    "   - Save as a new test case: `ambiguous_device_reference`\n",
    "   - Run evaluation - it likely passes but the agent might be confused\n",
    "\n",
    "2. **Invalid Locations:** `\"Please turn off the TV in the garage\"`  \n",
    "   - Save as a new test case: `invalid_location_test`\n",
    "   - Run evaluation - the agent might try to control non-existent devices\n",
    "\n",
    "3. **Complex Commands:** `\"Turn off all lights and turn on security system\"`\n",
    "   - Save as a new test case: `complex_multi_device_command`\n",
    "   - Run evaluation - the agent might attempt operations beyond its capabilities\n",
    "\n",
    "**The Problem You'll Discover:**\n",
    "Even when tests \"pass,\" you can see the agent:\n",
    "- Makes assumptions about devices that don't exist\n",
    "- Gives responses that sound helpful but aren't accurate\n",
    "- Tries to control devices it shouldn't have access to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfe471",
   "metadata": {},
   "source": [
    "## ðŸ¤” What am I missing?\n",
    "\n",
    "âŒ **Web UI Limitation:** So far, we've seen how to create and evaluate test cases in the ADK web UI. The web UI is great for interactive test creation, but testing one conversation at a time doesn't scale.\n",
    "\n",
    "â“ **The Question:** How do I proactively detect regressions in my agent's performance? \n",
    "\n",
    "Let's answer that question in the next section!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098474d",
   "metadata": {},
   "source": [
    "## â€¼ï¸ **Stop the ADK web UI** ðŸ›‘\n",
    "\n",
    "**In order to run cells in the remainder of this notebook,** please stop the running cell where you started `adk web` in Section 3.1.\n",
    "\n",
    "Otherwise that running cell will block / prevent other cells from running as long as the ADK web UI is running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1963d5e3",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“ˆ Systematic Evaluation\n",
    "\n",
    "Regression testing is the practice of re-running existing tests to ensure that new changes haven't broken previously working functionality.\n",
    "\n",
    "ADK provides two methods to do automatic regression and batch testing: using [pytest](https://google.github.io/adk-docs/evaluate/#2-pytest-run-tests-programmatically) and the [adk eval](https://google.github.io/adk-docs/evaluate/#3-adk-eval-run-evaluations-via-the-cli) CLI command. In this section, we'll use the CLI command. For more information on the `pytest` approach, refer to the links in the resource section at the end of this notebook.\n",
    "\n",
    "The following image shows the overall process of evaluation. **At a high-level, there are four steps to evaluate:**\n",
    "\n",
    "1) **Create an evaluation configuration** - define metrics or what you want to measure\n",
    "2) **Create test cases** - sample test cases to compare against\n",
    "3) **Run the agent with test query**\n",
    "4) **Compare the results**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1b4fef",
   "metadata": {},
   "source": [
    "![Evaluate](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/evaluate_agent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08111d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation configuration created!\n",
      "\n",
      "ðŸ“Š Evaluation Criteria:\n",
      "â€¢ tool_trajectory_avg_score: 1.0 - Requires exact tool usage match\n",
      "â€¢ response_match_score: 0.8 - Requires 80% text similarity\n",
      "\n",
      "ðŸŽ¯ What this evaluation will catch:\n",
      "âœ… Incorrect tool usage (wrong device, location, or status)\n",
      "âœ… Poor response quality and communication\n",
      "âœ… Deviations from expected behavior patterns\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Create evaluation configuration with basic criteria\n",
    "eval_config = {\n",
    "    \"criteria\": {\n",
    "        \"tool_trajectory_avg_score\": 1.0,  # Perfect tool usage required\n",
    "        \"response_match_score\": 0.8,  # 80% text similarity threshold\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"home_automation_agent/test_config.json\", \"w\") as f:\n",
    "    json.dump(eval_config, f, indent=2)\n",
    "\n",
    "print(\"âœ… Evaluation configuration created!\")\n",
    "print(\"\\nðŸ“Š Evaluation Criteria:\")\n",
    "print(\"â€¢ tool_trajectory_avg_score: 1.0 - Requires exact tool usage match\")\n",
    "print(\"â€¢ response_match_score: 0.8 - Requires 80% text similarity\")\n",
    "print(\"\\nðŸŽ¯ What this evaluation will catch:\")\n",
    "print(\"âœ… Incorrect tool usage (wrong device, location, or status)\")\n",
    "print(\"âœ… Poor response quality and communication\")\n",
    "print(\"âœ… Deviations from expected behavior patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e1c0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation test cases that reveal tool usage and response quality problems\n",
    "test_cases = {\n",
    "    \"eval_set_id\": \"home_automation_integration_suite\",\n",
    "    \"eval_cases\": [\n",
    "        {\n",
    "            \"eval_id\": \"living_room_light_on\",\n",
    "            \"conversation\": [\n",
    "                {\n",
    "                    \"user_content\": {\n",
    "                        \"parts\": [\n",
    "                            {\"text\": \"Please turn on the floor lamp in the living room\"}\n",
    "                        ]\n",
    "                    },\n",
    "                    \"final_response\": {\n",
    "                        \"parts\": [\n",
    "                            {\n",
    "                                \"text\": \"Successfully set the floor lamp in the living room to on.\"\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                    \"intermediate_data\": {\n",
    "                        \"tool_uses\": [\n",
    "                            {\n",
    "                                \"name\": \"set_device_status\",\n",
    "                                \"args\": {\n",
    "                                    \"location\": \"living room\",\n",
    "                                    \"device_id\": \"floor lamp\",\n",
    "                                    \"status\": \"ON\",\n",
    "                                },\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"eval_id\": \"kitchen_on_off_sequence\",\n",
    "            \"conversation\": [\n",
    "                {\n",
    "                    \"user_content\": {\n",
    "                        \"parts\": [{\"text\": \"Switch on the main light in the kitchen.\"}]\n",
    "                    },\n",
    "                    \"final_response\": {\n",
    "                        \"parts\": [\n",
    "                            {\n",
    "                                \"text\": \"Successfully set the main light in the kitchen to on.\"\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                    \"intermediate_data\": {\n",
    "                        \"tool_uses\": [\n",
    "                            {\n",
    "                                \"name\": \"set_device_status\",\n",
    "                                \"args\": {\n",
    "                                    \"location\": \"kitchen\",\n",
    "                                    \"device_id\": \"main light\",\n",
    "                                    \"status\": \"ON\",\n",
    "                                },\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e0ce9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation test cases created\n",
      "\n",
      "ðŸ§ª Test scenarios:\n",
      "â€¢ living_room_light_on: Please turn on the floor lamp in the living room\n",
      "â€¢ kitchen_on_off_sequence: Switch on the main light in the kitchen.\n",
      "\n",
      "ðŸ“Š Expected results:\n",
      "â€¢ basic_device_control: Should pass both criteria\n",
      "â€¢ wrong_tool_usage_test: May fail tool_trajectory if agent uses wrong parameters\n",
      "â€¢ poor_response_quality_test: May fail response_match if response differs too much\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"home_automation_agent/integration.evalset.json\", \"w\") as f:\n",
    "    json.dump(test_cases, f, indent=2)\n",
    "\n",
    "print(\"âœ… Evaluation test cases created\")\n",
    "print(\"\\nðŸ§ª Test scenarios:\")\n",
    "for case in test_cases[\"eval_cases\"]:\n",
    "    user_msg = case[\"conversation\"][0][\"user_content\"][\"parts\"][0][\"text\"]\n",
    "    print(f\"â€¢ {case['eval_id']}: {user_msg}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Expected results:\")\n",
    "print(\"â€¢ basic_device_control: Should pass both criteria\")\n",
    "print(\n",
    "    \"â€¢ wrong_tool_usage_test: May fail tool_trajectory if agent uses wrong parameters\"\n",
    ")\n",
    "print(\n",
    "    \"â€¢ poor_response_quality_test: May fail response_match if response differs too much\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cced5e",
   "metadata": {},
   "source": [
    "### Run CLI Evaluation\n",
    "\n",
    "Execute the `adk eval` command, pointing it to your agent directory, the evalset, and the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3967b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Run this command to execute evaluation:\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/metric_evaluator_registry.py:90: UserWarning: [EXPERIMENTAL] MetricEvaluatorRegistry: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  metric_evaluator_registry = MetricEvaluatorRegistry()\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/local_eval_service.py:79: UserWarning: [EXPERIMENTAL] UserSimulatorProvider: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  user_simulator_provider: UserSimulatorProvider = UserSimulatorProvider(),\n",
      "Using evaluation criteria: criteria={'tool_trajectory_avg_score': 1.0, 'response_match_score': 0.8} user_simulator_config=None\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/cli/cli_tools_click.py:650: UserWarning: [EXPERIMENTAL] UserSimulatorProvider: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  user_simulator_provider = UserSimulatorProvider(\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/cli/cli_tools_click.py:655: UserWarning: [EXPERIMENTAL] LocalEvalService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  eval_service = LocalEvalService(\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/user_simulator_provider.py:77: UserWarning: [EXPERIMENTAL] StaticUserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  return StaticUserSimulator(static_conversation=eval_case.conversation)\n",
      "/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/evaluation/static_user_simulator.py:39: UserWarning: [EXPERIMENTAL] UserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "2025-11-13 15:36:57,150 - INFO - plugin_manager.py:96 - Plugin 'request_intercepter_plugin' registered.\n",
      "2025-11-13 15:36:57,150 - WARNING - runners.py:266 - App name mismatch detected. The runner is configured with app name \"EvaluationGenerator\", but the root agent was loaded from \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n",
      "2025-11-13 15:36:57,200 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 15:36:57,201 - INFO - plugin_manager.py:96 - Plugin 'request_intercepter_plugin' registered.\n",
      "2025-11-13 15:36:57,201 - WARNING - runners.py:266 - App name mismatch detected. The runner is configured with app name \"EvaluationGenerator\", but the root agent was loaded from \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n",
      "2025-11-13 15:36:57,202 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 15:36:57,869 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 15:36:57,869 - WARNING - types.py:6324 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Tool Call: Setting main light in kitchen to ON\n",
      "2025-11-13 15:36:57,872 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 15:36:58,030 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 15:36:58,030 - WARNING - types.py:6324 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Tool Call: Setting floor lamp in living room to ON\n",
      "2025-11-13 15:36:58,032 - INFO - google_llm.py:133 - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-13 15:36:58,534 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 15:36:58,537 - INFO - google_llm.py:186 - Response received from the model.\n",
      "2025-11-13 15:36:58,541 - INFO - rouge_scorer.py:83 - Using default tokenizer.\n",
      "2025-11-13 15:36:58,542 - INFO - rouge_scorer.py:83 - Using default tokenizer.\n",
      "2025-11-13 15:36:58,542 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/home_automation_agent/.adk/eval_history/home_automation_agent_home_automation_integration_suite_1763044618.542581.evalset_result.json\n",
      "2025-11-13 15:36:58,544 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/home_automation_agent/.adk/eval_history/home_automation_agent_home_automation_integration_suite_1763044618.5439239.evalset_result.json\n",
      "*********************************************************************\n",
      "Eval Run Summary\n",
      "home_automation_integration_suite:\n",
      "  Tests passed: 0\n",
      "  Tests failed: 2\n",
      "********************************************************************\n",
      "Eval Set Id: home_automation_integration_suite\n",
      "Eval Id: kitchen_on_off_sequence\n",
      "Overall Eval Status: FAILED\n",
      "---------------------------------------------------------------------\n",
      "Metric: tool_trajectory_avg_score, Status: PASSED, Score: 1.0, Threshold: 1.0\n",
      "---------------------------------------------------------------------\n",
      "Metric: response_match_score, Status: FAILED, Score: 0.7, Threshold: 0.8\n",
      "---------------------------------------------------------------------\n",
      "Invocation Details:\n",
      "+----+--------------------------+---------------------------+---------------------------+---------------------------+---------------------------+-----------------------------+------------------------+\n",
      "|    | prompt                   | expected_response         | actual_response           | expected_tool_calls       | actual_tool_calls         | tool_trajectory_avg_score   | response_match_score   |\n",
      "+====+==========================+===========================+===========================+===========================+===========================+=============================+========================+\n",
      "|  0 | Switch on the main light | Successfully set the main | The main light in the     | id=None args={'location': | id='adk-2fffc76a-7f89-48a | Status: PASSED, Score:      | Status: FAILED, Score: |\n",
      "|    | in the kitchen.          | light in the kitchen to   | kitchen has been switched | 'kitchen', 'device_id':   | f- ac7e-c56139d2365e'     | 1.0                         | 0.7                    |\n",
      "|    |                          | on.                       | on.                       | 'main light', 'status':   | args={'status': 'ON',     |                             |                        |\n",
      "|    |                          |                           |                           | 'ON'}                     | 'device_id': 'main        |                             |                        |\n",
      "|    |                          |                           |                           | name='set_device_status'  | light', 'location':       |                             |                        |\n",
      "|    |                          |                           |                           |                           | 'kitchen'}                |                             |                        |\n",
      "|    |                          |                           |                           |                           | name='set_device_status'  |                             |                        |\n",
      "+----+--------------------------+---------------------------+---------------------------+---------------------------+---------------------------+-----------------------------+------------------------+\n",
      "\n",
      "\n",
      "\n",
      "********************************************************************\n",
      "Eval Set Id: home_automation_integration_suite\n",
      "Eval Id: living_room_light_on\n",
      "Overall Eval Status: FAILED\n",
      "---------------------------------------------------------------------\n",
      "Metric: tool_trajectory_avg_score, Status: PASSED, Score: 1.0, Threshold: 1.0\n",
      "---------------------------------------------------------------------\n",
      "Metric: response_match_score, Status: FAILED, Score: 0.7272727272727273, Threshold: 0.8\n",
      "---------------------------------------------------------------------\n",
      "Invocation Details:\n",
      "+----+--------------------------+--------------------------+-----------------------+---------------------------+---------------------------+-----------------------------+------------------------+\n",
      "|    | prompt                   | expected_response        | actual_response       | expected_tool_calls       | actual_tool_calls         | tool_trajectory_avg_score   | response_match_score   |\n",
      "+====+==========================+==========================+=======================+===========================+===========================+=============================+========================+\n",
      "|  0 | Please turn on the floor | Successfully set the     | The floor lamp in the | id=None args={'location': | id='adk-f84aabca-1483-40a | Status: PASSED, Score:      | Status: FAILED, Score: |\n",
      "|    | lamp in the living room  | floor lamp in the living | living room has been  | 'living room',            | 1-84f1- 8788bddee819'     | 1.0                         | 0.7272727272727273     |\n",
      "|    |                          | room to on.              | turned on.            | 'device_id': 'floor       | args={'device_id': 'floor |                             |                        |\n",
      "|    |                          |                          |                       | lamp', 'status': 'ON'}    | lamp', 'status': 'ON',    |                             |                        |\n",
      "|    |                          |                          |                       | name='set_device_status'  | 'location': 'living       |                             |                        |\n",
      "|    |                          |                          |                       |                           | room'}                    |                             |                        |\n",
      "|    |                          |                          |                       |                           | name='set_device_status'  |                             |                        |\n",
      "+----+--------------------------+--------------------------+-----------------------+---------------------------+---------------------------+-----------------------------+------------------------+\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸš€ Run this command to execute evaluation:\")\n",
    "!adk eval home_automation_agent home_automation_agent/integration.evalset.json --config_file_path=home_automation_agent/test_config.json --print_detailed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46430b6",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“š User Simulation (Optional)\n",
    "\n",
    "While **traditional evaluation methods rely on fixed test cases**, real-world conversations are dynamic and unpredictable. This is where User Simulation comes in.\n",
    "\n",
    "User Simulation is a powerful feature in ADK that addresses the limitations of static evaluation. Instead of using pre-defined, fixed user prompts, User Simulation employs a generative AI model (like Gemini) to **dynamically generate user prompts during the evaluation process.**\n",
    "\n",
    "### â“ How it works\n",
    "\n",
    "* You define a `ConversationScenario` that outlines the user's overall conversational goals and a `conversation_plan` to guide the dialogue.\n",
    "* A large language model (LLM) then acts as a simulated user, using this plan and the ongoing conversation history to generate realistic and varied prompts.\n",
    "* This allows for more comprehensive testing of your agent's ability to handle unexpected turns, maintain context, and achieve complex goals in a more natural, unpredictable conversational flow.\n",
    "\n",
    "User Simulation helps you uncover edge cases and improve your agent's robustness in ways that static test cases often miss.\n",
    "\n",
    "### ðŸ‘‰ Exercise\n",
    "\n",
    "Now that you understand the power of User Simulation for dynamic agent evaluation, here's an exercise to apply it:\n",
    "\n",
    "Apply the **User Simulation** feature to your agent. Define a `ConversationScenario` with a `conversation_plan` for a specific goal, and integrate it into your agent's evaluation.\n",
    "\n",
    "**â­ Refer to this [documentation](https://google.github.io/adk-docs/evaluate/user-sim/) to learn how to do it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4974f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
