{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0927d205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "try: \n",
    "    google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "    os.environ['GOOGLE_API_KEY'] = google_api_key\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "    print(\"âœ… Gemini API key setup complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e146d64",
   "metadata": {},
   "source": [
    "# ðŸ§  Memory Management - Memory\n",
    "\n",
    "\n",
    "In the previous notebook, you learned how **Sessions** manage conversation threads. Now you'll add **Memory** - a searchable, long-term knowledge store that persists across multiple conversations.\n",
    "\n",
    "### What is Memory â“\n",
    "\n",
    "Memory is a service that provides long-term knowledge storage for your agents. The key distinction:\n",
    "\n",
    "> **Session = Short-term memory** (single conversation)\n",
    "> \n",
    "> **Memory = Long-term knowledge** (across multiple conversations)\n",
    "\n",
    "Think of it in software engineering terms: **Session** is like application state (temporary), while **Memory** is like a database (persistent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e1143",
   "metadata": {},
   "source": [
    "### ðŸ¤” Why Memory?\n",
    "\n",
    "Memory provides capabilities that Sessions alone cannot:\n",
    "\n",
    "| Capability | What It Means | Example |\n",
    "|------------|---------------|---------|\n",
    "| **Cross-Conversation Recall** | Access information from any past conversation | \"What preferences has this user mentioned across all chats?\" |\n",
    "| **Intelligent Extraction** | LLM-powered consolidation extracts key facts | Stores \"allergic to peanuts\" instead of 50 raw messages |\n",
    "| **Semantic Search** | Meaning-based retrieval, not just keyword matching | Query \"preferred hue\" matches \"favorite color is blue\" |\n",
    "| **Persistent Storage** | Survives application restarts | Build knowledge that grows over time |\n",
    "\n",
    "**Example:** Imagine talking to a personal assistant:\n",
    "- ðŸ—£ï¸ **Session**: They remember what you said 10 minutes ago in THIS conversation\n",
    "- ðŸ§  **Memory**: They remember your preferences from conversations LAST WEEK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402cdcae",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ What you'll learn:\n",
    "\n",
    "- âœ… Initialize MemoryService and integrate with your agent\n",
    "- âœ… Transfer session data to memory storage\n",
    "- âœ… Search and retrieve memories\n",
    "- âœ… Automate memory storage and retrieval\n",
    "- âœ… Understand memory consolidation (conceptual overview)\n",
    "\n",
    "#### ðŸ“ Implementation Note\n",
    "\n",
    "> This notebook uses `InMemoryMemoryService` for learning - it performs keyword matching and doesn't persist data. \n",
    ">\n",
    "> For production applications, use **Vertex AI Memory Bank** (covered in Day 5), which provides LLM-powered consolidation and semantic search with persistent cloud storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2072d750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "from google.adk.tools import load_memory, preload_memory\n",
    "from google.genai import types\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af28a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "async def run_session(\n",
    "    runner_instance: Runner, user_queries: list[str] | str, session_id: str = \"default\"\n",
    "):\n",
    "    \"\"\"Helper function to run queries in a session and display responses.\"\"\"\n",
    "    print(f\"\\n### Session: {session_id}\")\n",
    "\n",
    "    # Create or retrieve session\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n",
    "        )\n",
    "\n",
    "    # Convert single query to list\n",
    "    if isinstance(user_queries, str):\n",
    "        user_queries = [user_queries]\n",
    "\n",
    "    # Process each query\n",
    "    for query in user_queries:\n",
    "        print(f\"\\nUser > {query}\")\n",
    "        query_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "        # Stream agent response\n",
    "        async for event in runner_instance.run_async(\n",
    "            user_id=USER_ID, session_id=session.id, new_message=query_content\n",
    "        ):\n",
    "            if event.is_final_response() and event.content and event.content.parts:\n",
    "                text = event.content.parts[0].text\n",
    "                if text and text != \"None\":\n",
    "                    print(f\"Model: > {text}\")\n",
    "\n",
    "\n",
    "print(\"âœ… Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e619b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ac7db",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ¤“ Memory Workflow\n",
    "\n",
    "From the Introduction section, you now know why we need Memory. In order to integrate Memory into your Agents, there are **three high-level steps.**\n",
    "\n",
    "**Three-step integration process:**\n",
    "\n",
    "1. **Initialize** â†’ Create a `MemoryService` and provide it to your agent via the `Runner`\n",
    "2. **Ingest** â†’ Transfer session data to memory using `add_session_to_memory()`\n",
    "3. **Retrieve** â†’ Search stored memories using `search_memory()`\n",
    "\n",
    "Let's explore each step in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10a9cc",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/memory-workflow.png\" width=\"1400\" alt=\"Memory workflow\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e5cbf",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ§  Initialize MemoryService"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34061589",
   "metadata": {},
   "source": [
    "###  Initialize Memory\n",
    "\n",
    "ADK provides multiple `MemoryService` implementations through the `BaseMemoryService` interface:\n",
    "\n",
    "- **`InMemoryMemoryService`** - Built-in service for prototyping and testing (keyword matching, no persistence)\n",
    "- **`VertexAiMemoryBankService`** - Managed cloud service with LLM-powered consolidation and semantic search\n",
    "- **Custom implementations** - You can build your own using databases, though managed services are recommended\n",
    "\n",
    "For this notebook, we'll use `InMemoryMemoryService` to learn the core mechanics. The same methods work identically with production-ready services like Vertex AI Memory Bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec410b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_service = (\n",
    "    InMemoryMemoryService()\n",
    ")  # ADK's built-in Memory Service for development and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0618837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent created\n"
     ]
    }
   ],
   "source": [
    "# Define constants used throughout the notebook\n",
    "APP_NAME = \"MemoryDemoApp\"\n",
    "USER_ID = \"demo_user\"\n",
    "\n",
    "# Create agent\n",
    "user_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"MemoryDemoAgent\",\n",
    "    instruction=\"Answer user questions in simple words.\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57330436",
   "metadata": {},
   "source": [
    "#### **Create Runner**\n",
    "\n",
    "Now provide both Session and Memory services to the `Runner`.\n",
    "\n",
    "**Key configuration:**\n",
    "\n",
    "The `Runner` requires both services to enable memory functionality:\n",
    "- **`session_service`** â†’ Manages conversation threads and events\n",
    "- **`memory_service`** â†’ Provides long-term knowledge storage\n",
    "\n",
    "Both services work together: Sessions capture conversations, Memory stores knowledge for retrieval across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c923cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "App name mismatch detected. The runner is configured with app name \"MemoryDemoApp\", but the root agent was loaded from \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent and Runner created with memory support!\n"
     ]
    }
   ],
   "source": [
    "# Create Session Service\n",
    "session_service = InMemorySessionService()  # Handles conversations\n",
    "\n",
    "# Create runner with BOTH services\n",
    "runner = Runner(\n",
    "    agent=user_agent,\n",
    "    app_name=\"MemoryDemoApp\",\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,  # Memory service is now available!\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent and Runner created with memory support!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4f1d4",
   "metadata": {},
   "source": [
    "### â€¼ï¸ Important\n",
    "\n",
    "**ðŸ’¡ Configuration vs. Usage:** Adding `memory_service` to the `Runner` makes memory *available* to your agent, but doesn't automatically use it. You must explicitly:\n",
    "1. **Ingest data** using `add_session_to_memory()` \n",
    "2. **Enable retrieval** by giving your agent memory tools (`load_memory` or `preload_memory`)\n",
    "\n",
    "Let's learn these steps next!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa4ab32",
   "metadata": {},
   "source": [
    "### MemoryService Implementation Options\n",
    "\n",
    "**This notebook: `InMemoryMemoryService`**\n",
    "- Stores raw conversation events without consolidation\n",
    "- Keyword-based search (simple word matching)\n",
    "- In-memory storage (resets on restart)\n",
    "- Ideal for learning and local development\n",
    "\n",
    "**Production: `VertexAiMemoryBankService` (You'll learn this on Day 5)**\n",
    "- LLM-powered extraction of key facts\n",
    "- Semantic search (meaning-based retrieval)\n",
    "- Persistent cloud storage\n",
    "- Integrates external knowledge sources\n",
    "\n",
    "**ðŸ’¡ API Consistency:** Both implementations use identical methods (`add_session_to_memory()`, `search_memory()`). The workflow you learn here applies to all memory services!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a522aee",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Ingest Session Data into Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d28a85",
   "metadata": {},
   "source": [
    "**Why should you transfer Session data to Memory?**\n",
    "\n",
    "Now that memory is initialized, you need to populate it with knowledge. When you initialize a MemoryService, it starts completely empty. All your conversations are stored in Sessions, which contain raw events including every message, tool call, and metadata. To make this information available for long-term recall, you explicitly transfer it to memory using `add_session_to_memory()`.\n",
    "\n",
    "Here's where managed memory services like Vertex AI Memory Bank shine. **During transfer, they perform intelligent consolidation - extracting key facts while discarding conversational noise.** The `InMemoryMemoryService` we're using stores everything without consolidation, which is sufficient for learning the mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1facebd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: conversation-01\n",
      "\n",
      "User > My favorite color is blue-green. Can you write a Haiku about it?\n",
      "Model: > A gentle ocean,\n",
      "Or a fresh, green, leafy sprout,\n",
      "Calm, peaceful, and cool.\n"
     ]
    }
   ],
   "source": [
    "# User tells agent about their favorite color\n",
    "await run_session(\n",
    "    runner,\n",
    "    \"My favorite color is blue-green. Can you write a Haiku about it?\",\n",
    "    \"conversation-01\",  # Session ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af9bf41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Session contains:\n",
      "  user: My favorite color is blue-green. Can you write a Haiku about...\n",
      "  model: A gentle ocean,\n",
      "Or a fresh, green, leafy sprout,\n",
      "Calm, peace...\n"
     ]
    }
   ],
   "source": [
    "session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"conversation-01\"\n",
    ")\n",
    "\n",
    "# Let's see what's in the session\n",
    "print(\"ðŸ“ Session contains:\")\n",
    "for event in session.events:\n",
    "    text = (\n",
    "        event.content.parts[0].text[:60]\n",
    "        if event.content and event.content.parts\n",
    "        else \"(empty)\"\n",
    "    )\n",
    "    print(f\"  {event.content.role}: {text}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da4acfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Session added to memory!\n"
     ]
    }
   ],
   "source": [
    "# This is the key method!\n",
    "await memory_service.add_session_to_memory(session)\n",
    "\n",
    "print(\"âœ… Session added to memory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae33701",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”Ž Enable Memory Retrieval in Your Agent\n",
    "\n",
    "You've successfully transferred session data to memory, but there's one crucial step remaining. **Agents can't directly access the MemoryService - they need tools to search it.** \n",
    "\n",
    "This is by design: it gives you control over when and how memory is retrieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca1cdbc",
   "metadata": {},
   "source": [
    "### Memory Retrieval in ADK\n",
    "\n",
    "ADK provides two built-in tools for memory retrieval:\n",
    "\n",
    "**`load_memory` (Reactive)**\n",
    "- Agent decides when to search memory\n",
    "- Only retrieves when the agent thinks it's needed\n",
    "- More efficient (saves tokens)\n",
    "- Risk: Agent might forget to search\n",
    "\n",
    "**`preload_memory` (Proactive)**\n",
    "- Automatically searches before every turn\n",
    "- Memory always available to the agent\n",
    "- Guaranteed context, but less efficient\n",
    "- Searches even when not needed\n",
    "\n",
    "Think of it like studying for an exam: `load_memory` is looking things up only when you need them, while `preload_memory` is reading all your notes before answering each question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ce5b8",
   "metadata": {},
   "source": [
    "### Add Load Memory Tool to Agent\n",
    "\n",
    "Let's start by implementing the reactive pattern. We'll recreate the agent from Section 3, this time adding the `load_memory` tool to its toolkit. Since this is a built-in ADK tool, you simply include it in the tools array without any custom implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26dd9b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent with load_memory tool created.\n"
     ]
    }
   ],
   "source": [
    "# Create agent\n",
    "user_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"MemoryDemoAgent\",\n",
    "    instruction=\"Answer user questions in simple words. Use load_memory tool if you need to recall past conversations.\",\n",
    "    tools=[\n",
    "        load_memory\n",
    "    ],  # Agent now has access to Memory and can search it whenever it decides to!\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent with load_memory tool created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c31d6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "App name mismatch detected. The runner is configured with app name \"MemoryDemoApp\", but the root agent was loaded from \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: color-test\n",
      "\n",
      "User > What is my favorite color?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: > The user's favorite color is blue-green.\n"
     ]
    }
   ],
   "source": [
    "# Create a new runner with the updated agent\n",
    "runner = Runner(\n",
    "    agent=user_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,\n",
    ")\n",
    "\n",
    "await run_session(runner, \"What is my favorite color?\", \"color-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca193c",
   "metadata": {},
   "source": [
    "### Complete Manual Workflow Test\n",
    "\n",
    "Let's see the complete workflow in action. We'll have a conversation about a birthday, manually save it to memory, then test retrieval in a new session. This demonstrates the full cycle: **ingest â†’ store â†’ retrieve**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76456953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: birthday-session-01\n",
      "\n",
      "User > My birthday is on March 15th.\n",
      "Model: > Okay, I will remember that your birthday is on March 15th.\n"
     ]
    }
   ],
   "source": [
    "await run_session(runner, \"My birthday is on March 15th.\", \"birthday-session-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d05bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Birthday session saved to memory!\n"
     ]
    }
   ],
   "source": [
    "# Manually save the session to memory\n",
    "birthday_session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"birthday-session-01\"\n",
    ")\n",
    "\n",
    "await memory_service.add_session_to_memory(birthday_session)\n",
    "\n",
    "print(\"âœ… Birthday session saved to memory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92818ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: birthday-session-02\n",
      "\n",
      "User > When is my birthday?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: > Your birthday is on March 15th.\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval in a NEW session\n",
    "await run_session(\n",
    "    runner, \"When is my birthday?\", \"birthday-session-02\"  # Different session ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeaad79",
   "metadata": {},
   "source": [
    "#### ðŸš€ Your Turn: Experiment with Both Patterns\n",
    "\n",
    "Try swapping `load_memory` with `preload_memory` by changing the tools array to `tools=[preload_memory]`.\n",
    "\n",
    "**What changes:**\n",
    "- `load_memory` (reactive): Agent decides when to search\n",
    "- `preload_memory` (proactive): Automatically loads memory before every turn\n",
    "\n",
    "**Test it:**\n",
    "1. Ask \"What is my favorite color?\" in a new session\n",
    "2. Ask \"Tell me a joke\" - notice that `preload_memory` still searches memory even though it's unnecessary\n",
    "3. Which pattern is better for different use cases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f006554",
   "metadata": {},
   "source": [
    "### Manual Memory Search\n",
    "\n",
    "Beyond agent tools, you can also search memories directly in your code. This is useful for:\n",
    "- Debugging memory contents\n",
    "- Building analytics dashboards  \n",
    "- Creating custom memory management UIs\n",
    "\n",
    "The `search_memory()` method takes a text query and returns a `SearchMemoryResponse` with matching memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b71eeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Search Results:\n",
      "  Found 3 relevant memories\n",
      "\n",
      "  [user]: My favorite color is blue-green. Can you write a Haiku about it?...\n",
      "  [user]: My birthday is on March 15th....\n",
      "  [MemoryDemoAgent]: Okay, I will remember that your birthday is on March 15th....\n"
     ]
    }
   ],
   "source": [
    "# Search for color preferences\n",
    "search_response = await memory_service.search_memory(\n",
    "    app_name=APP_NAME, user_id=USER_ID, query=\"What is the user's favorite color?\"\n",
    ")\n",
    "\n",
    "print(\"ðŸ” Search Results:\")\n",
    "print(f\"  Found {len(search_response.memories)} relevant memories\")\n",
    "print()\n",
    "\n",
    "for memory in search_response.memories:\n",
    "    if memory.content and memory.content.parts:\n",
    "        text = memory.content.parts[0].text[:80]\n",
    "        print(f\"  [{memory.author}]: {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6508e",
   "metadata": {},
   "source": [
    "### How Search Works\n",
    "\n",
    "**InMemoryMemoryService (this notebook):**\n",
    "- **Method:** Keyword matching\n",
    "- **Example:** \"favorite color\" matches because those exact words exist\n",
    "- **Limitation:** \"preferred hue\" won't match\n",
    "\n",
    "**VertexAiMemoryBankService (Day 5):**\n",
    "- **Method:** Semantic search via embeddings\n",
    "- **Example:** \"preferred hue\" WILL match \"favorite color\"\n",
    "- **Advantage:** Understands meaning, not just keywords\n",
    "\n",
    "You'll explore semantic search in Day 5!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b53e51e",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ¤– Automating Memory Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f886d",
   "metadata": {},
   "source": [
    "So far, we've **manually** called `add_session_to_memory()` to transfer data to long-term storage. Production systems need this to happen **automatically**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1fe4f",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "ADK's callback system lets you hook into key execution moments. Callbacks are **Python functions** you define and attach to agents - ADK automatically calls them at specific stages, acting like checkpoints during the agent's execution flow.\n",
    "\n",
    "**Think of callbacks as event listeners in your agent's lifecycle.** When an agent processes a request, it goes through multiple stages: receiving the input, calling the LLM, invoking tools, and generating the response. Callbacks let you insert custom logic at each of these stages without modifying the core agent code.\n",
    "\n",
    "**Available callback types:**\n",
    "\n",
    "- `before_agent_callback` â†’ Runs before agent starts processing a request\n",
    "- `after_agent_callback` â†’ Runs after agent completes its turn  \n",
    "- `before_tool_callback` / `after_tool_callback` â†’ Around tool invocations\n",
    "- `before_model_callback` / `after_model_callback` â†’ Around LLM calls\n",
    "- `on_model_error_callback` â†’ When errors occur\n",
    "\n",
    "**Common use cases:**\n",
    "\n",
    "- Logging and observability (track what the agent does)\n",
    "- Automatic data persistence (like saving to memory)\n",
    "- Custom validation or filtering\n",
    "- Performance monitoring\n",
    "\n",
    "**ðŸ“š Learn More:** [ADK Callbacks Documentation](https://google.github.io/adk-docs/agents/callbacks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af507ac",
   "metadata": {},
   "source": [
    "![image.png](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/types_of_callbacks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a57ae",
   "metadata": {},
   "source": [
    "### Automatic Memory Storage with Callbacks\n",
    "\n",
    "For automatic memory storage, we'll use `after_agent_callback`. This function triggers every time the agent finishes a turn, then calls `add_session_to_memory()` to persist the conversation automatically.\n",
    "\n",
    "But here's the challenge: how does our callback function actually access the memory service and current session? That's where `callback_context` comes in.\n",
    "\n",
    "When you define a callback function, ADK automatically passes a special parameter called `callback_context` to it. The `callback_context` provides access to the Memory Service and other runtime components.\n",
    "\n",
    "**How we'll use it:** In our callback, we'll access the memory service and current session to automatically save conversation data after each turn.\n",
    "\n",
    "**ðŸ’¡ Important:** You don't create this context - ADK creates it and passes it to your callback automatically when the callback runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd101e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Callback created.\n"
     ]
    }
   ],
   "source": [
    "async def auto_save_to_memory(callback_context):\n",
    "    \"\"\"Automatically save session to memory after each agent turn.\"\"\"\n",
    "    await callback_context._invocation_context.memory_service.add_session_to_memory(\n",
    "        callback_context._invocation_context.session\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"âœ… Callback created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def2f71",
   "metadata": {},
   "source": [
    "### Create an Agent: Callback and PreLoad Memory Tool\n",
    "\n",
    "Now create an agent that combines:\n",
    "- **Automatic storage:** `after_agent_callback` saves conversations\n",
    "- **Automatic retrieval:** `preload_memory` loads memories\n",
    "\n",
    "This creates a fully automated memory system with zero manual intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbe12c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent created with automatic memory saving!\n"
     ]
    }
   ],
   "source": [
    "# Agent with automatic memory saving\n",
    "auto_memory_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"AutoMemoryAgent\",\n",
    "    instruction=\"Answer user questions.\",\n",
    "    tools=[preload_memory],\n",
    "    after_agent_callback=auto_save_to_memory,  # Saves after each turn!\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent created with automatic memory saving!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948331e3",
   "metadata": {},
   "source": [
    "**What happens automatically:**\n",
    "\n",
    "- After every agent response â†’ callback triggers\n",
    "- Session data â†’ transferred to memory\n",
    "- No manual `add_session_to_memory()` calls needed\n",
    "\n",
    "The framework handles everything!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253db80b",
   "metadata": {},
   "source": [
    "### Create a Runner and Test The Agent\n",
    "\n",
    "Time to test! Create a Runner with the auto-memory agent, connecting the session and memory services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "530add16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "App name mismatch detected. The runner is configured with app name \"MemoryDemoApp\", but the root agent was loaded from \"/Users/soroushav/Desktop/kaggle/5_day_agenticai_intensive_course/venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Runner created.\n"
     ]
    }
   ],
   "source": [
    "# Create a runner for the auto-save agent\n",
    "# This connects our automated agent to the session and memory services\n",
    "auto_runner = Runner(\n",
    "    agent=auto_memory_agent,  # Use the agent with callback + preload_memory\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,  # Same services from Section 3\n",
    "    memory_service=memory_service,\n",
    ")\n",
    "\n",
    "print(\"âœ… Runner created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d5c07eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: auto-save-test\n",
      "\n",
      "User > I gifted a new toy to my nephew on his 1st birthday!\n",
      "Model: > That's wonderful! A 1st birthday is such a special milestone. I hope your nephew loves his new toy!\n",
      "\n",
      "### Session: auto-save-test-2\n",
      "\n",
      "User > What did I gift my nephew?\n",
      "Model: > You gifted your nephew a new toy.\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Tell the agent about a gift (first conversation)\n",
    "# The callback will automatically save this to memory when the turn completes\n",
    "await run_session(\n",
    "    auto_runner,\n",
    "    \"I gifted a new toy to my nephew on his 1st birthday!\",\n",
    "    \"auto-save-test\",\n",
    ")\n",
    "\n",
    "# Test 2: Ask about the gift in a NEW session (second conversation)\n",
    "# The agent should retrieve the memory using preload_memory and answer correctly\n",
    "await run_session(\n",
    "    auto_runner,\n",
    "    \"What did I gift my nephew?\",\n",
    "    \"auto-save-test-2\",  # Different session ID - proves memory works across sessions!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b945bb9",
   "metadata": {},
   "source": [
    "**What just happened:**\n",
    "\n",
    "1. **First conversation:** Mentioned gift to nephew\n",
    "   - Callback automatically saved to memory âœ…\n",
    "2. **Second conversation (new session):** Asked about the gift  \n",
    "   - `preload_memory` automatically retrieved the memory âœ…\n",
    "   - Agent answered correctly âœ…\n",
    "\n",
    "**Zero manual memory calls!** This is automated memory management in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90746f5",
   "metadata": {},
   "source": [
    "### How often should you save Sessions to Memory?\n",
    "\n",
    "**Options:**\n",
    "\n",
    "| Timing | Implementation | Best For |\n",
    "|--------|----------------|----------|\n",
    "| **After every turn** | `after_agent_callback` | Real-time memory updates |\n",
    "| **End of conversation** | Manual call when session ends | Batch processing, reduce API calls |\n",
    "| **Periodic intervals** | Timer-based background job | Long-running conversations |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24474eb1",
   "metadata": {},
   "source": [
    "## ðŸ§© Memory Consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f3393",
   "metadata": {},
   "source": [
    "### The Limitation of Raw Storage\n",
    "\n",
    "**What we've stored so far:**\n",
    "- Every user message\n",
    "- Every agent response  \n",
    "- Every tool call\n",
    "\n",
    "**The problem:**\n",
    "```\n",
    "Session: 50 messages = 10,000 tokens\n",
    "Memory:  All 50 messages stored\n",
    "Search:  Returns all 50 messages â†’ Agent must process 10,000 tokens\n",
    "```\n",
    "\n",
    "This doesn't scale. We need **consolidation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4054c45",
   "metadata": {},
   "source": [
    "### What is Memory Consolidation?\n",
    "\n",
    "**Memory Consolidation** = Extracting **only important facts** while discarding conversational noise.\n",
    "\n",
    "**Before (Raw Storage):**\n",
    "\n",
    "```\n",
    "User: \"My favorite color is BlueGreen. I also like purple. \n",
    "       Actually, I prefer BlueGreen most of the time.\"\n",
    "Agent: \"Great! I'll remember that.\"\n",
    "User: \"Thanks!\"\n",
    "Agent: \"You're welcome!\"\n",
    "\n",
    "â†’ Stores ALL 4 messages (redundant, verbose)\n",
    "```\n",
    "\n",
    "**After (Consolidation):**\n",
    "\n",
    "```\n",
    "Extracted Memory: \"User's favorite color: BlueGreen\"\n",
    "\n",
    "â†’ Stores 1 concise fact\n",
    "```\n",
    "\n",
    "**Benefits:** Less storage, faster retrieval, more accurate answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07e0a7d",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/memory-consolidation.png\" width=\"1400\" alt=\"Memory consolidation\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb293918",
   "metadata": {},
   "source": [
    "### How Consolidation Works (Conceptual)\n",
    "\n",
    "**The pipeline:**\n",
    "\n",
    "```\n",
    "1. Raw Session Events\n",
    "   â†“\n",
    "2. LLM analyzes conversation\n",
    "   â†“\n",
    "3. Extracts key facts\n",
    "   â†“\n",
    "4. Stores concise memories\n",
    "   â†“\n",
    "5. Merges with existing memories (deduplication)\n",
    "```\n",
    "\n",
    "**Example transformation:**\n",
    "\n",
    "```\n",
    "Input:  \"I'm allergic to peanuts. I can't eat anything with nuts.\"\n",
    "\n",
    "Output: Memory {\n",
    "  allergy: \"peanuts, tree nuts\"\n",
    "  severity: \"avoid completely\"\n",
    "}\n",
    "```\n",
    "\n",
    "Natural language â†’ Structured, actionable data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60629337",
   "metadata": {},
   "source": [
    "### Next Steps for Memory Consolidation\n",
    "\n",
    "**ðŸ’¡ Key Point:** Managed Memory Services handle consolidation **automatically**. \n",
    "\n",
    "**You use the same API:**\n",
    "- `add_session_to_memory()` â† Same method\n",
    "- `search_memory()` â† Same method\n",
    "\n",
    "**The difference:** What happens behind the scenes.\n",
    "- **InMemoryMemoryService:** Stores raw events\n",
    "- **VertexAiMemoryBankService:** Intelligently consolidates before storing\n",
    "\n",
    "**ðŸ“š Learn More:**\n",
    "- [Vertex AI Memory Bank: Memory Consolidation Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/generate-memories) -> You'll explore this in Day 5!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22987c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
